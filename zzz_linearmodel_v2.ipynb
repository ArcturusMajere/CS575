{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q4mQ7jm9GW5k",
    "outputId": "9ad25e98-5e13-4183-f55c-0deb3803871b"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "file_path1 = 'C:/temp/X_train.csv';file_path2 = 'C:/temp/y_train.csv'\n",
    "file_path3 = 'C:/temp/X_test.csv'; file_path4 = 'C:/temp/y_test.csv'\n",
    "X1 = pd.read_csv(file_path1);y1 = pd.read_csv(file_path2)\n",
    "X2 = pd.read_csv(file_path3);y2 = pd.read_csv(file_path4)\n",
    "X_train = np.array(X1);X_test = np.array(X2)\n",
    "y_train = np.array(y1).flatten();y_test = np.array(y2).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.79692948, -0.25628095],\n",
       "       [-0.11010756, -0.37411937],\n",
       "       [ 0.3224064 ,  0.9704698 ],\n",
       "       [-1.27629731, -0.3407025 ],\n",
       "       [ 0.65889623, -0.2712306 ],\n",
       "       [-0.23960413, -0.31695894],\n",
       "       [ 0.18617211,  0.72599904],\n",
       "       [-0.75126704, -0.29761233],\n",
       "       [-0.75889266, -0.37851633],\n",
       "       [-1.37136406, -0.35301398],\n",
       "       [-1.20959179, -0.36444607],\n",
       "       [-1.3035699 , -0.37851633],\n",
       "       [-0.4287365 , -0.28266268],\n",
       "       [ 0.02270382, -0.3512552 ],\n",
       "       [-0.95989197,  1.92021232],\n",
       "       [-0.93703827, -0.30640625],\n",
       "       [-1.23464078, -0.3204765 ],\n",
       "       [-0.54648709,  1.33453776],\n",
       "       [-1.50989402, -0.38643085]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[1:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6yPuAcpnU3-2",
    "outputId": "aa4f37a4-b7f3-41a5-cb71-324297f638d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------------------------+------------------+--------------+---------+-----------+------------+\n",
      "| Data       | Type                    | Shape            | MissingVals  | Size(MB)| Mean      | SD         |\n",
      "+------------+-------------------------+------------------+--------------+---------+-----------+------------+\n",
      "| X_train   | <class 'numpy.ndarray'>  | (10400792, 2)    | 0            | 158.70  | 0.00      | 0.99       |\n",
      "| y_train   | <class 'numpy.ndarray'>  | (10400792,)      | 0            | 79.35   | 0.66      | 0.47       |\n",
      "| X_test    | <class 'numpy.ndarray'>  | (2764768, 2)     | 0            | 42.19   | -0.01     | 1.05       |\n",
      "| y_test    | <class 'numpy.ndarray'>  | (2764768,)       | 0            | 21.09   | 0.64      | 0.48       |\n",
      "+------------+-------------------------+------------------+--------------+---------+-----------+------------+\n"
     ]
    }
   ],
   "source": [
    "# numpy only data peek\n",
    "\n",
    "def data_info(data):\n",
    "    missing_values = np.isnan(data).sum()\n",
    "    size_in_mb = data.nbytes / (1024 ** 2)\n",
    "    if len(data.shape) > 1:\n",
    "        mean = data.mean()\n",
    "        sd = data.std()\n",
    "    else:\n",
    "        mean = np.mean(data)\n",
    "        sd = np.std(data)\n",
    "    return missing_values, size_in_mb, mean, sd\n",
    "\n",
    "def data_summary(X_train, y_train, X_test, y_test):\n",
    "    header = \"+------------+-------------------------+------------------+--------------+---------+-----------+------------+\"\n",
    "    print(header)\n",
    "    print(\"| Data       | Type                    | Shape            | MissingVals  | Size(MB)| Mean      | SD         |\")\n",
    "    print(header)\n",
    "\n",
    "    for name, data in [(\"X_train\", X_train), (\"y_train\", y_train), (\"X_test\", X_test), (\"y_test\", y_test)]:\n",
    "        missing_values, size_in_mb, mean, sd = data_info(data)\n",
    "        print(\"| {:<9} | {:<24} | {:<16} | {:<12} | {:<7.2f} | {:<9.2f} | {:<10.2f} |\".format(\n",
    "            name, str(type(data)), str(data.shape), missing_values, size_in_mb, mean, sd))\n",
    "    print(header)\n",
    "\n",
    "\n",
    "data_summary(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "GEbHhMSnGR3T"
   },
   "outputs": [],
   "source": [
    "# Binary target: logisitic regression which is acutally classificaiton.\n",
    "\n",
    "class LogisticRegression:\n",
    "\n",
    "    def __init__(self, lr=0.01, num_iter=1000):\n",
    "        self.lr = lr\n",
    "        self.num_iter = num_iter\n",
    "\n",
    "    def sigmoid(self, z):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # initialization of weights\n",
    "        self.theta = np.zeros(X.shape[1])\n",
    "        self.bias = 0\n",
    "\n",
    "        for i in range(self.num_iter):\n",
    "            model = np.dot(X, self.theta) + self.bias\n",
    "            predictions = self.sigmoid(model)\n",
    "\n",
    "            # compute gradient\n",
    "            d_theta = (1 / len(X)) * np.dot(X.T, (predictions - y))\n",
    "            d_bias = (1 / len(X)) * np.sum(predictions - y)\n",
    "\n",
    "            # update my weights\n",
    "            self.theta -= self.lr * d_theta\n",
    "            self.bias -= self.lr * d_bias\n",
    "\n",
    "    def predict_prob(self, X):\n",
    "        return self.sigmoid(np.dot(X, self.theta) + self.bias)\n",
    "\n",
    "    def predict(self, X, threshold=0.5):\n",
    "        return (self.predict_prob(X) >= threshold).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "0s09ZN77N8Sg"
   },
   "outputs": [],
   "source": [
    "def confusion_matrix(y_true, y_pred):\n",
    "    TP = np.sum((y_true == 1) & (y_pred == 1))\n",
    "    TN = np.sum((y_true == 0) & (y_pred == 0))\n",
    "    FP = np.sum((y_true == 0) & (y_pred == 1))\n",
    "    FN = np.sum((y_true == 1) & (y_pred == 0))\n",
    "    return TP, TN, FP, FN\n",
    "\n",
    "def accuracy(TP, TN, FP, FN):\n",
    "    return (TP + TN) / (TP + TN + FP + FN)\n",
    "\n",
    "def specificity(TN, FP):\n",
    "    return TN / (TN + FP)\n",
    "\n",
    "def sensitivity(TP, FN):\n",
    "    return TP / (TP + FN)\n",
    "\n",
    "def f1_score(TP, FP, FN):\n",
    "    precision = TP / (TP + FP)\n",
    "    recall = TP / (TP + FN)\n",
    "    return 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "def print_confusion_matrix(TP, TN, FP, FN):\n",
    "    head_cm = \"+-----------------+------------+\"\n",
    "    print(head_cm)\n",
    "    print(\"|                 | Predicted  |\")\n",
    "    print(\"| Actual          | 0    | 1    |\")\n",
    "    print(head_cm)\n",
    "    print(\"| 0               | {:<5} | {:<5} |\".format(TN, FP))\n",
    "    print(\"| 1               | {:<5} | {:<5} |\".format(FN, TP))\n",
    "    print(head_cm)\n",
    "    print()\n",
    "\n",
    "def metrics(y_true, y_pred):\n",
    "    TP, TN, FP, FN = confusion_matrix(y_true, y_pred)\n",
    "    acc = accuracy(TP, TN, FP, FN)\n",
    "    spec = specificity(TN, FP)\n",
    "    sens = sensitivity(TP, FN)\n",
    "    f1 = f1_score(TP, FP, FN)\n",
    "\n",
    "    print_confusion_matrix(TP, TN, FP, FN)\n",
    "\n",
    "    head = \"+--------------+---------+\"\n",
    "    print(head)\n",
    "    print(\"| Metric       | Value   |\")\n",
    "    print(head)\n",
    "    print(\"| Accuracy     | {:.4f} |\".format(acc))\n",
    "    print(\"| Specificity  | {:.4f} |\".format(spec))\n",
    "    print(\"| Sensitivity  | {:.4f} |\".format(sens))\n",
    "    print(\"| F1 Score     | {:.4f} |\".format(f1))\n",
    "    print(head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 366
    },
    "id": "rGHjxDFMGR3T",
    "outputId": "5ec07e9a-77b7-42c5-ce20-33f2241101af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+------------+\n",
      "|                 | Predicted  |\n",
      "| Actual          | 0    | 1    |\n",
      "+-----------------+------------+\n",
      "| 0               | 0     | 982339 |\n",
      "| 1               | 0     | 1782429 |\n",
      "+-----------------+------------+\n",
      "\n",
      "+--------------+---------+\n",
      "| Metric       | Value   |\n",
      "+--------------+---------+\n",
      "| Accuracy     | 0.6447 |\n",
      "| Specificity  | 0.0000 |\n",
      "| Sensitivity  | 1.0000 |\n",
      "| F1 Score     | 0.7840 |\n",
      "+--------------+---------+\n"
     ]
    }
   ],
   "source": [
    "model_logreg = LogisticRegression(lr=0.01, num_iter=10)\n",
    "model_logreg.fit(X_train, y_train)\n",
    "y_pred_logreg = model_logreg.predict(X_test)\n",
    "metrics(y_test, y_pred_logreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KUGJyH2ZGR3S",
    "outputId": "e0066b8f-6ffe-4841-e8f9-cb66f660f248"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean squared error:  64.35492876641504\n",
      "mean absolute error:  64.47533782344999\n",
      "mean root mean error:  80.22152377411878\n",
      "r2 value:  -1.809477617267969\n"
     ]
    }
   ],
   "source": [
    "# grad desect method\n",
    "\n",
    "def calc_cost(X, y, theta):\n",
    "    m = len(y)\n",
    "    cost = (1/2*m) * np.sum(np.square(X.dot(theta) - y))\n",
    "    return cost\n",
    "\n",
    "def grad_desc(X, y, theta, lr, iters):\n",
    "    m = len(y)\n",
    "    cost_hist = np.zeros(iters)\n",
    "\n",
    "    for i in range(iters):\n",
    "        theta = theta - (1/m) * lr * (X.T.dot(X.dot(theta) - y))\n",
    "        cost_hist[i] = calc_cost(X, y, theta)\n",
    "\n",
    "    return theta, cost_hist\n",
    "\n",
    "# initial coeffx w/intercept)\n",
    "theta = np.zeros(X_train.shape[1])\n",
    "\n",
    "#  gradient-descent settings\n",
    "iters = 500\n",
    "lr = 0.0001\n",
    "\n",
    "# Run gradient-descent\n",
    "theta, cost_hist = grad_desc(X_train, y_train, theta, lr, iters)\n",
    "\n",
    "pred = X_test.dot(theta)\n",
    "mae = np.mean(np.abs(pred - y_test))\n",
    "mse = np.mean((pred - y_test)**2)\n",
    "rmse = np.sqrt(np.mean((pred - y_test)**2))\n",
    "ss_res = np.sum((pred - y_test)**2)\n",
    "ss_tot = np.sum((y_test - np.mean(y_test))**2)\n",
    "r2 = 1 - (ss_res / ss_tot)\n",
    "print(\"mean squared error: \",mse*100)\n",
    "print(\"mean absolute error: \",mae*100)\n",
    "print(\"mean root mean error: \",rmse*100)\n",
    "print(\"r2 value: \",r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+------------+\n",
      "|                 | Predicted  |\n",
      "| Actual          | 0    | 1    |\n",
      "+-----------------+------------+\n",
      "| 0               | 0     | 0     |\n",
      "| 1               | 0     | 0     |\n",
      "+-----------------+------------+\n",
      "\n",
      "+--------------+---------+\n",
      "| Metric       | Value   |\n",
      "+--------------+---------+\n",
      "| Accuracy     | nan |\n",
      "| Specificity  | nan |\n",
      "| Sensitivity  | nan |\n",
      "| F1 Score     | nan |\n",
      "+--------------+---------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\12084\\AppData\\Local\\Temp\\ipykernel_17076\\3056985081.py:9: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return (TP + TN) / (TP + TN + FP + FN)\n",
      "C:\\Users\\12084\\AppData\\Local\\Temp\\ipykernel_17076\\3056985081.py:12: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return TN / (TN + FP)\n",
      "C:\\Users\\12084\\AppData\\Local\\Temp\\ipykernel_17076\\3056985081.py:15: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return TP / (TP + FN)\n",
      "C:\\Users\\12084\\AppData\\Local\\Temp\\ipykernel_17076\\3056985081.py:18: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  precision = TP / (TP + FP)\n",
      "C:\\Users\\12084\\AppData\\Local\\Temp\\ipykernel_17076\\3056985081.py:19: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  recall = TP / (TP + FN)\n"
     ]
    }
   ],
   "source": [
    "metrics(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(X, y, theta):\n",
    "    m = len(y)\n",
    "    cost = (1/2*m) * np.sum(np.square(X.dot(theta) - y))\n",
    "    return cost\n",
    "\n",
    "def gradient_descent(X, y, theta, learning_rate, iterations):\n",
    "    m = len(y)\n",
    "    cost_history = np.zeros(iterations)\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        theta = theta - (1/m) * learning_rate * (X.T.dot(X.dot(theta) - y))\n",
    "        cost_history[i] = compute_cost(X, y, theta)\n",
    "    \n",
    "    return theta, cost_history\n",
    "\n",
    "# initial coeffx w/intercept)\n",
    "theta = np.zeros(X.shape[1])\n",
    "\n",
    "# abritrary gradient-descent settings\n",
    "iters = 200\n",
    "lr = 0.01\n",
    "\n",
    "# Run gradient-descent\n",
    "theta, cost_history = gradient_descent(X_train, y_train, theta, lr, iters)\n",
    "\n",
    "pred = X_test.dot(theta)\n",
    "mae = np.mean(np.abs(pred - y_test))\n",
    "mse = np.mean((pred - y_test)**2)\n",
    "rmse = np.sqrt(np.mean((pred - y_test)**2))\n",
    "ss_res = np.sum((pred - y_test)**2)\n",
    "ss_tot = np.sum((y_test - np.mean(y_test))**2)\n",
    "r2 = 1 - (ss_res / ss_tot)\n",
    "\n",
    "print(\"mean squared error: \",mse*100)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
